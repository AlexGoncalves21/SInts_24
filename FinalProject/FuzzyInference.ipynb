{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyfume'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfume\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mClustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Clusterer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfume\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEstimateAntecendentSet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AntecedentEstimator\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyfume\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEstimateConsequentParameters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConsequentEstimator\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyfume'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyfume.Clustering import Clusterer\n",
    "from pyfume.EstimateAntecendentSet import AntecedentEstimator\n",
    "from pyfume.EstimateConsequentParameters import ConsequentEstimator\n",
    "from pyfume.SimpfulModelBuilder import SugenoFISBuilder\n",
    "from pyfume.Tester import SugenoFISTester\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "from numpy import clip, column_stack, argmax\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('dataTrain.csv')\n",
    "Test = pd.read_csv('dataTest.csv')\n",
    "\n",
    "stats = pd.read_csv('stats.csv')\n",
    "stats.columns = ['var', 'mean', 'std']\n",
    "\n",
    "X_train = Train.drop('output', axis=1)\n",
    "y_train = Train['output']\n",
    "\n",
    "X_test = Test.drop('output', axis=1)\n",
    "y_test = Test['output']\n",
    "\n",
    "maxs = X_train.max().tolist()\n",
    "mins = X_train.min().tolist()\n",
    "\n",
    "var_names = X_train.columns.to_list()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savecols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.array\n",
    "y_test = y_test.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try out different numbers of clusters in order to minimize the separation between clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparationMetric(X_train, clust_centers, part_matrix):\n",
    "    metric = 0\n",
    "    for clust in range(clust_centers.shape[0]):\n",
    "        for point in range(X_train.shape[0]):\n",
    "            metric += part_matrix[point, clust] * distance.euclidean(X_train[point], clust_centers[clust])\n",
    "    return metric\n",
    "\n",
    "#def SeparationMetric(X_train, clust_centers, part_matrix):\n",
    "#    silhouette_score(X_train, )\n",
    "#    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since pyfume's clustering algorithm was using the the target, I made some modifcations to their fcm\n",
    "# code as seen below\n",
    "\n",
    "def fcm(data, n_clusters, m=2, max_iter=1000, error=0.005):\n",
    "        #data: 2d array, size (N, S). N is the number of instances; S is the number of variables\n",
    "        #n_clusters: number of clusters\n",
    "        #m: fuzzy clustering coefficient\n",
    "        #max_it: maximum number of iterations, default=1000\n",
    "        #error: stopping criterion, default=0.005\n",
    "        #seed: seed for random initialization of u matrix\n",
    "        \n",
    "    n_instances = data.shape[0]\n",
    "        \n",
    "    #randomly initaliaze u\n",
    "    np.random.seed(1231241421)\n",
    "    u = np.random.rand(n_instances, n_clusters)\n",
    "    u = np.fmax(u, np.finfo(np.float64).eps)\n",
    "    ut = u.T\n",
    "        \n",
    "    for it in range(0,max_iter):\n",
    "        #copy old u matrix\n",
    "        u_old = ut.copy()\n",
    "        u_old /= np.ones((n_clusters, 1)).dot(np.atleast_2d(u_old.sum(axis=0)))\n",
    "        u_old = np.fmax(u_old, np.finfo(np.float64).eps)\n",
    "        \n",
    "        #elevate to m\n",
    "        um = u_old ** m\n",
    "        \n",
    "        #calculate cluster centers\n",
    "        centers = um.dot(data) / (np.ones((data.shape[1], 1)).dot(np.atleast_2d(um.sum(axis=1))).T)\n",
    "        \n",
    "        #calculate distances\n",
    "        dist = cdist(centers, data, metric='euclidean')\n",
    "        dist = np.fmax(dist, np.finfo(np.float64).eps)\n",
    "        \n",
    "        #calculate objective\n",
    "        jm = (um * dist ** 2).sum()\n",
    "    \n",
    "        #calculate new u matrix\n",
    "        ut = dist ** (- 2. / (m - 1))\n",
    "        ut /= np.ones((n_clusters, 1)).dot(np.atleast_2d(ut.sum(axis=0)))\n",
    "    \n",
    "        #stopping criterion\n",
    "        if np.linalg.norm(ut - u_old) < error:\n",
    "            break\n",
    "    \n",
    "    partition_matrix = ut.T\n",
    "    return centers, partition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(nclusters):\n",
    "    clust_centers, part_matrix = fcm(X_train, n_clusters = nclusters)\n",
    "    return clust_centers, part_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = 2\n",
    "min_metric = np.inf\n",
    "\n",
    "for i in range(max_clusters):\n",
    "    i += 1\n",
    "    clust_centers, part_matrix = Cluster(i)\n",
    "    metric = SeparationMetric(X_train, clust_centers, part_matrix)\n",
    "    if metric < min_metric:\n",
    "        min_metric = metric\n",
    "        best_number = i\n",
    "\n",
    "print(f'Best number of clusters: {best_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_centers, part_matrix = Cluster(best_number)\n",
    "clust_centers.shape, part_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AntecedentEstimator(X_train, part_matrix)\n",
    "antecedent_params = ae.determineMF()\n",
    "\n",
    "ce = ConsequentEstimator(X_train, y_train, part_matrix)\n",
    "conseq_params = ce.suglms()\n",
    "\n",
    "modbuilder = SugenoFISBuilder(antecedent_params, conseq_params, var_names, save_simpful_code=False)\n",
    "model = modbuilder.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modtester = SugenoFISTester(model, X_test, var_names)\n",
    "y_pred_probs = clip(modtester.predict()[0], 0, 1)\n",
    "y_pred_probs = column_stack((1 - y_pred_probs, y_pred_probs))\n",
    "y_pred = argmax(y_pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_score))\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "print(\"Recall: {:.3f}\".format(rec_score))\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "print(\"Precision Score: {:.3f}\".format(prec_score))\n",
    "F1_score = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score: {:.3f}\".format(F1_score))\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Kappa Score: {:.3f}\".format(kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization/Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._lvs['chol'] # example of how pyFUME defines une linguistic variable in simpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_rules() # print the rules associated with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pyFUME library doesn't atribute a universe of discourse to the linguistic variables it creates in simpful. In order to fix this, we set each universe considering the maximum\n",
    "# value heald by each dataframe column. This has to be done since, otherwise, the plotting functions won't work.\n",
    "\n",
    "for ix in range(len(var_names)):\n",
    "    max = maxs[ix]\n",
    "    min = mins[ix]\n",
    "    uod = [min, max]\n",
    "    model._lvs[var_names[ix]]._universe_of_discourse = uod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.produce_figure(\"\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionsToZ(model, stats):\n",
    "    for f in model._outputfunctions:\n",
    "        expression = model._outputfunctions[f]\n",
    "        item_list = expression.split('+')\n",
    "        for k in range(len(item_list) - 1):\n",
    "            item_list[k] = item_list[k].split('*')\n",
    "            values = stats[stats['var'] == item_list[k][1]]\n",
    "            item_list[k][0] = float(item_list[k][0]) * values.iloc[0,2] + values.iloc[0,1]\n",
    "        finalfunct = ''\n",
    "        for sum in item_list:\n",
    "            if len(sum) != 1: finalfunct = finalfunct + str(sum[0]) + '*' + sum[1] + '+'\n",
    "        finalfunct = finalfunct[:-4] + str(item_list[-1])\n",
    "        model._outputfunctions[f] = finalfunct\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClusterstoZ(model, stats):\n",
    "    for lv in model._lvs:\n",
    "        data = stats[stats['var'] == lv]\n",
    "        mean = data.iloc[0,1]\n",
    "        std = data.iloc[0,2]\n",
    "        dict = model._lvs[lv]._FSlist[0]._funpointer\n",
    "        dict._mu = 140#dict._mu - mean  #confirmar\n",
    "        dict._sigma = dict._sigma + std - 1#confirmar\n",
    "        model._lvs[lv]._FSlist[0]._funpointer = dict\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UODtoZ(model, stats):\n",
    "    for lv in model._lvs:\n",
    "        data = stats[stats['var'] == lv]\n",
    "        mean = data.iloc[0,1]\n",
    "        std = data.iloc[0,2]\n",
    "        uod = model._lvs[lv]._universe_of_discourse\n",
    "        for i in range(2):\n",
    "            uod[i] = uod[i] * std + mean\n",
    "        model._lvs[lv]._universe_of_discourse = uod\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelZ = FunctionsToZ(model, stats)\n",
    "modelZ = ClusterstoZ(modelZ, stats)\n",
    "modelZ = UODtoZ(modelZ, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelZ.produce_figure(\"\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(modelZ._lvs['chol']._FSlist[0]._funpointer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
