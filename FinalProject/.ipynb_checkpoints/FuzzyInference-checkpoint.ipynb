{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pyfume.Clustering import Clusterer\n",
    "from pyfume.EstimateAntecendentSet import AntecedentEstimator\n",
    "from pyfume.EstimateConsequentParameters import ConsequentEstimator\n",
    "from pyfume.SimpfulModelBuilder import SugenoFISBuilder\n",
    "from pyfume.Tester import SugenoFISTester\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, cohen_kappa_score\n",
    "from numpy import clip, column_stack, argmax\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.metrics import silhouette_score\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('dataTrain.csv')\n",
    "Test = pd.read_csv('dataTest.csv')\n",
    "\n",
    "stats = pd.read_csv('stats.csv')\n",
    "stats = stats.iloc[:,1:]\n",
    "\n",
    "X_train = Train.drop('output', axis=1)\n",
    "y_train = Train['output']\n",
    "\n",
    "X_test = Test.drop('output', axis=1)\n",
    "y_test = Test['output']\n",
    "\n",
    "maxs = X_train.max().tolist()\n",
    "mins = X_train.min().tolist()\n",
    "\n",
    "var_names = X_train.columns.to_list()\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savecols = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.array\n",
    "y_test = y_test.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try out different numbers of clusters in order to minimize the separation between clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SeparationMetric(X_train, clust_centers, part_matrix):\n",
    "    metric = 0\n",
    "    for clust in range(clust_centers.shape[0]):\n",
    "        for point in range(X_train.shape[0]):\n",
    "            metric += part_matrix[point, clust] * distance.euclidean(X_train[point], clust_centers[clust])\n",
    "    return metric\n",
    "\n",
    "#def SeparationMetric(X_train, clust_centers, part_matrix):\n",
    "#    silhouette_score(X_train, )\n",
    "#    return metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since pyfume's clustering algorithm was using the the target, I made some modifcations to their fcm\n",
    "# code as seen below\n",
    "\n",
    "def fcm(data, n_clusters, m=2, max_iter=1000, error=0.005):\n",
    "        #data: 2d array, size (N, S). N is the number of instances; S is the number of variables\n",
    "        #n_clusters: number of clusters\n",
    "        #m: fuzzy clustering coefficient\n",
    "        #max_it: maximum number of iterations, default=1000\n",
    "        #error: stopping criterion, default=0.005\n",
    "        #seed: seed for random initialization of u matrix\n",
    "        \n",
    "    n_instances = data.shape[0]\n",
    "        \n",
    "    #randomly initaliaze u\n",
    "    np.random.seed(1231241421)\n",
    "    u = np.random.rand(n_instances, n_clusters)\n",
    "    u = np.fmax(u, np.finfo(np.float64).eps)\n",
    "    ut = u.T\n",
    "        \n",
    "    for it in range(0,max_iter):\n",
    "        #copy old u matrix\n",
    "        u_old = ut.copy()\n",
    "        u_old /= np.ones((n_clusters, 1)).dot(np.atleast_2d(u_old.sum(axis=0)))\n",
    "        u_old = np.fmax(u_old, np.finfo(np.float64).eps)\n",
    "        \n",
    "        #elevate to m\n",
    "        um = u_old ** m\n",
    "        \n",
    "        #calculate cluster centers\n",
    "        centers = um.dot(data) / (np.ones((data.shape[1], 1)).dot(np.atleast_2d(um.sum(axis=1))).T)\n",
    "        \n",
    "        #calculate distances\n",
    "        dist = cdist(centers, data, metric='euclidean')\n",
    "        dist = np.fmax(dist, np.finfo(np.float64).eps)\n",
    "        \n",
    "        #calculate objective\n",
    "        jm = (um * dist ** 2).sum()\n",
    "    \n",
    "        #calculate new u matrix\n",
    "        ut = dist ** (- 2. / (m - 1))\n",
    "        ut /= np.ones((n_clusters, 1)).dot(np.atleast_2d(ut.sum(axis=0)))\n",
    "    \n",
    "        #stopping criterion\n",
    "        if np.linalg.norm(ut - u_old) < error:\n",
    "            break\n",
    "    \n",
    "    partition_matrix = ut.T\n",
    "    return centers, partition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cluster(nclusters):\n",
    "    clust_centers, part_matrix = fcm(X_train, n_clusters = nclusters)\n",
    "    return clust_centers, part_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, mu, sig):\n",
    "    #return (1.0 / (np.sqrt(2.0 * np.pi) * sig) * np.exp(-np.power((x - mu) / sig, 2.0) / 2))\n",
    "    return (np.exp(-np.power((x - mu) / sig, 2.0) / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_clusters = 2\n",
    "min_metric = np.inf\n",
    "\n",
    "for i in range(max_clusters):\n",
    "    i += 1\n",
    "    clust_centers, part_matrix = Cluster(i)\n",
    "    metric = SeparationMetric(X_train, clust_centers, part_matrix)\n",
    "    if metric < min_metric:\n",
    "        min_metric = metric\n",
    "        best_number = i\n",
    "\n",
    "print(f'Best number of clusters: {best_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_centers, part_matrix = Cluster(best_number)\n",
    "clust_centers.shape, part_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming Cluster and SeparationMetric functions are defined elsewhere\n",
    "\n",
    "max_clusters = 2\n",
    "min_metric = np.inf\n",
    "metrics = []  # List to store metrics for each number of clusters\n",
    "\n",
    "# Loop through different numbers of clusters\n",
    "for i in range(1, max_clusters + 1):\n",
    "    clust_centers, part_matrix = Cluster(i)\n",
    "    metric = SeparationMetric(X_train, clust_centers, part_matrix)\n",
    "    \n",
    "    metrics.append(metric)  # Store the metric for the current number of clusters\n",
    "    \n",
    "    if metric < min_metric:\n",
    "        min_metric = metric\n",
    "        best_number = i\n",
    "\n",
    "# Print the best number of clusters\n",
    "print(f'Best number of clusters: {best_number}')\n",
    "\n",
    "# Plotting the evolution of metrics\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, max_clusters + 1), metrics, marker='o', linestyle='-', color='b')\n",
    "plt.title('Evolution of Separation Metric Over Number of Clusters')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Separation Metric')\n",
    "plt.grid()\n",
    "plt.axvline(best_number, color='r', linestyle='--', label=f'Best Number of Clusters: {best_number}')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AntecedentEstimator(X_train, part_matrix)\n",
    "antecedent_params = ae.determineMF()\n",
    "\n",
    "ce = ConsequentEstimator(X_train, y_train, part_matrix)\n",
    "conseq_params = ce.suglms()\n",
    "\n",
    "modbuilder = SugenoFISBuilder(antecedent_params, conseq_params, var_names, save_simpful_code=False)\n",
    "model = modbuilder.get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modtester = SugenoFISTester(model, X_test, var_names)\n",
    "y_pred_probs = clip(modtester.predict()[0], 0, 1)\n",
    "y_pred_probs = column_stack((1 - y_pred_probs, y_pred_probs))\n",
    "y_pred = argmax(y_pred_probs,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:.3f}\".format(acc_score))\n",
    "rec_score = recall_score(y_test, y_pred)\n",
    "print(\"Recall: {:.3f}\".format(rec_score))\n",
    "prec_score = precision_score(y_test, y_pred)\n",
    "print(\"Precision Score: {:.3f}\".format(prec_score))\n",
    "F1_score = f1_score(y_test, y_pred)\n",
    "print(\"F1-Score: {:.3f}\".format(F1_score))\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "print(\"Kappa Score: {:.3f}\".format(kappa))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization/Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._lvs['chol'] # example of how pyFUME defines une linguistic variable in simpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_rules() # print the rules associated with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pyFUME library doesn't atribute a universe of discourse to the linguistic variables it creates in simpful. In order to fix this, we set each universe considering the maximum\n",
    "# value heald by each dataframe column. This has to be done since, otherwise, the plotting functions won't work.\n",
    "\n",
    "for ix in range(len(var_names)):\n",
    "    max = maxs[ix]\n",
    "    min = mins[ix]\n",
    "    uod = [min, max]\n",
    "    model._lvs[var_names[ix]]._universe_of_discourse = uod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.produce_figure(\"\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the model to X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionstoX(model, stats):\n",
    "    final_df = pd.DataFrame(columns = var_names+['constant'])\n",
    "\n",
    "    for f in model._outputfunctions:\n",
    "        acumulated = 0 # value to be added to the intercept in the end\n",
    "        expression = model._outputfunctions[f]\n",
    "        item_list = expression.split('+')\n",
    "\n",
    "        for k in range(len(item_list) - 1):\n",
    "            item_list[k] = item_list[k].split('*')\n",
    "            values = stats[stats['Feature'] == item_list[k][1]]\n",
    "            std = values.iloc[0,2] ** 0.5\n",
    "            mean = values.iloc[0,1]\n",
    "            acumulated += float(item_list[k][0]) * mean\n",
    "            item_list[k] = float(item_list[k][0]) * (std) \n",
    "            \n",
    "        item_list[-1] = float(item_list[-1]) + acumulated\n",
    "        final_df = pd.concat([final_df,pd.DataFrame([item_list], columns = var_names+['constant'])], axis = 0)\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UODtoX(model, stats):\n",
    "    uods = {}\n",
    "    for lv in model._lvs:\n",
    "        data = stats[stats['Feature'] == lv]\n",
    "        mean = data.iloc[0,1]\n",
    "        std = data.iloc[0,2] ** 0.5\n",
    "        uod = model._lvs[lv]._universe_of_discourse\n",
    "        for i in range(2):\n",
    "            uod[i] = uod[i] * std + mean\n",
    "        uods[lv] = uod\n",
    "    return uods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XMF:\n",
    "\n",
    "    def __init__(self, uod, data, mu, sigma):\n",
    "        self.uod = uod\n",
    "        self.mean = data.iloc[0,1]\n",
    "        self.std = data.iloc[0,2] ** 0.5\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \n",
    "        x = (x - self.mean) / self.std \n",
    "        x = gaussian(x, self.mu, self.sigma)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newMFS(model, stats, uods):\n",
    "    MFS = {}\n",
    "    for lv in model._lvs:\n",
    "        fs = []\n",
    "        data = stats[stats['Feature'] == lv]\n",
    "        uod = uods[lv]\n",
    "        for clust in range(len(model._lvs[lv]._FSlist)):\n",
    "            mu = model._lvs[lv]._FSlist[clust]._funpointer._mu\n",
    "            sigma = model._lvs[lv]._FSlist[clust]._funpointer._sigma\n",
    "            fs.append(XMF(uod, data, mu, sigma))\n",
    "        MFS[lv] = fs\n",
    "    return MFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMFs(mfs, var):\n",
    "    mfs = mfs[var]\n",
    "    x = np.linspace(mfs[0].uod[0], mfs[0].uod[1], 100)\n",
    "    for i in range(len(mfs)):\n",
    "        y = [mfs[i](j) for j in x]\n",
    "        plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uods = UODtoX(model, stats)\n",
    "mfs = newMFS(model, stats, uods)\n",
    "consequents = FunctionstoX(model, stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estado Atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMFs(mfs, 'thalachh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duvidas\n",
    "\n",
    "# A soma dos valores obtidos pelos consequentes é igual a uma probabilidade?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
